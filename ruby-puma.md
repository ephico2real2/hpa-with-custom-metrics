Here's a basic explanation of your recent work with custom metrics for a Ruby application designed to work in containers:

1. **Instrumenting the Ruby App**:
   - Developers added the Prometheus Ruby gem called `puma` to the Ruby application. This gem is used to automatically instrument the application, enabling it to generate traffic and expose relevant metrics.

2. **Creating a Prometheus Adapter**:
   - A Prometheus adapter was created to expose the custom metrics generated by `puma`. This adapter acts as a bridge, allowing Prometheus to scrape and collect these custom metrics.

3. **Updating Kubernetes Deployment Helm Chart**:
   - The Kubernetes deployment Helm chart was updated to include Prometheus scraping annotations. These annotations instruct Prometheus to scrape the metrics endpoint exposed by the Ruby application.

4. **Validating Metrics Using Prometheus Query in Thanos**:
   - The collected metrics were validated using Prometheus queries (PromQL) in Thanos. This step ensures that the metrics are correctly collected and can be queried effectively.

5. **Creating a New Horizontal Pod Autoscaler (HPA)**:
   - A new HPA was created to utilize the `puma` worker Prometheus custom metrics. The HPA dynamically adjusts the number of pod replicas based on the custom metrics, ensuring optimal resource utilization.

6. **Profiling the App**:
   - The application was profiled with the developer by testing and validating the thresholds. This step involved fine-tuning the metrics and thresholds to ensure the HPA responds appropriately to changes in traffic and load.

These steps collectively enabled the Ruby application to utilize custom metrics for better monitoring, scaling, and performance optimization within a containerized environment.
